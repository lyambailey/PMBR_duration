{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "The purpose of this script is to load \"long\" epoch TFRs for both the button-press (BP) and resting-state tasks, and concatenate data dfrom each task into:\n",
    "1. A channels x epochs x frequencies x timepoints array\n",
    "2. A channels x epochs x timepoints array, averaged over the beta frequency range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "mne.set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define data directories and filenames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path (from which we will read files)\n",
    "data_path =  os.path.join(\"/media/NAS/lbailey/PMBR_timecourse/output/proc_data\")\n",
    "\n",
    "# Output path (where we will save files)\n",
    "out_path = os.path.join(\"/media/NAS/lbailey/PMBR_timecourse/output/1BP15\")\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "# Define generic filenames\n",
    "rest_suffix = '_epoch_tfrs_no_baseline_1s-pre_15s-post_3-min_rest-tfr.h5'\n",
    "bp_suffix = '_epoch_tfrs_no_baseline_1s-pre_15s-post_trial-tfr.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import subject list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of subjects from the demographics csv\n",
    "df_demo_allsubjects = pd.read_csv(\"/home/timb/camcan/proc_data/demographics_allSubjects.csv\")\n",
    "subject_list = list(df_demo_allsubjects.loc[(df_demo_allsubjects['RawExists'] == 1)]['SubjectID'])\n",
    "\n",
    "# Remove the following subjects from subject_list. These subjects either had missing rest data, or ICA failed to converge on their BP data\n",
    "missing_subjects = ['CC620685', 'CC620444', 'CC120208', 'CC621118', 'CC410097', \n",
    "                    'CC620557', 'CC723197', 'CC221733', 'CC711244', 'CC720330', \n",
    "                    'CC620567', 'CC122016', 'CC512003', 'CC610462', 'CC510480']\n",
    "\n",
    "for i in missing_subjects:\n",
    "    subject_list.remove(i)\n",
    "\n",
    "# Also note that CC621080 has BP data but no rest data, because ICA failed for the latter. \n",
    "# We'll keep this subject because we are primarily concerned with BP data; but it's worth \n",
    "# noting that the rest data is missing from one subject.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a function to read tfr data (rest or BP) from individual subjects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tfr(subject, task):\n",
    "   \n",
    "    # Define path to tfr file for this subject and task\n",
    "    tfr_fname =  os.path.join(data_path, subject, subject + eval(f'{task}_suffix'))\n",
    "    \n",
    "    if not os.path.exists(tfr_fname):\n",
    "        print(f'The {task} tfr file for {subject} does not exist. Skipping...')\n",
    "        return\n",
    "\n",
    "    # Load the tfr. Note that tfr has the form (n_epochs, n_channels, n_freqs, n_times)\n",
    "    tfr = mne.time_frequency.read_tfrs(tfr_fname)\n",
    "\n",
    "    # Append subjectID\n",
    "    # tfr.subject = subject\n",
    "\n",
    "    return tfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define empty lists to store imported TFRs, and keep track of participant and epoch counts for each task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty list to store tfr data from each task\n",
    "tfrs_bp = []\n",
    "tfrs_rest = []\n",
    "\n",
    "# Keep track of any skipped subjects (e.g., due to missing data)\n",
    "skipped_subjects_bp = []\n",
    "skipped_subjects_rest = []\n",
    "\n",
    "# Count epochs per participant\n",
    "n_epochs_bp = []\n",
    "n_epochs_rest = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the tfrs for each task and append to respective numpy arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop through all subjects and load their TFR data\n",
    "for i, subject in enumerate(tqdm(subject_list[:1])):\n",
    "\n",
    "    for task in ['bp', 'rest']:\n",
    "\n",
    "        # Determine which containers we will store data in, depending on the task\n",
    "        tfrs = eval(f'tfrs_{task}')\n",
    "        skipped_subjects = eval(f'skipped_subjects_{task}')\n",
    "        n_epochs = eval(f'n_epochs_{task}')\n",
    "\n",
    "        # Load the tfr data. We'll use a try statement here because some subjects return None\n",
    "        try:\n",
    "            orig_tfr = load_tfr(subject, task)\n",
    "\n",
    "            tfrs.append(orig_tfr.get_data())\n",
    "            n_epochs.append(orig_tfr.get_data().shape[0])\n",
    "\n",
    "            # Also get info, times and freqs from the first subject\n",
    "            if i == 0:                \n",
    "                info = orig_tfr.info\n",
    "                times = orig_tfr.times\n",
    "                freqs = orig_tfr.freqs\n",
    "\n",
    "                # Save to disk\n",
    "                mne.io.write_info(os.path.join(out_path, f'{task}-info.fif'), info)\n",
    "                np.save(os.path.join(out_path, f'{task}_times.npy'), times)\n",
    "                np.save(os.path.join(out_path, f'{task}_freqs.npy'), freqs)\n",
    "\n",
    "        except:\n",
    "            skipped_subjects.append(subject)\n",
    "            continue\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out participant & epoch counts for each task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print total number of epochs\n",
    "print(f'Total number of epochs in BP task: {sum(n_epochs_bp)}')\n",
    "print(f'Total number of epochs in rest task: {sum(n_epochs_rest)}')\n",
    "\n",
    "# Print total number of subjects\n",
    "n_subjects_bp = len(subject_list) - len(skipped_subjects_bp)\n",
    "n_subjects_rest = len(subject_list) - len(skipped_subjects_rest)\n",
    "\n",
    "print(f'Number of subjects in BP task: {n_subjects_bp}')\n",
    "print(f'Number of subjects in rest task: {n_subjects_rest}')\n",
    "\n",
    "# Print total number of subjects with only one epoch\n",
    "print(f'Number of subjects with only one epoch in BP task: {len([i for i in n_epochs_bp if i == 1])}')\n",
    "\n",
    "# Print out any skipped subjects\n",
    "print(f'Skipped subjects in BP task: {len(skipped_subjects_bp)}')\n",
    "print(f'Skipped subjects in rest task: {len(skipped_subjects_rest)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate lists of TFRs into one array per task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrs_bp_concat = np.concatenate(tfrs_bp, axis=0)\n",
    "tfrs_rest_concat = np.concatenate(tfrs_rest, axis=0)\n",
    "\n",
    "# Print shape of the new arrays\n",
    "print(f'Shape of concatenated BP data: {tfrs_bp_concat.shape}')\n",
    "print(f'Shape of concatenated rest data: {tfrs_rest_concat.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the concatenated arrays to disk\n",
    "np.save(os.path.join(out_path, f'tfr_data_BP_{n_subjects_bp}_subjects.npy'), tfrs_bp_concat)\n",
    "np.save(os.path.join(out_path, f'tfr_data_rest_{n_subjects_rest}_subjects.npy'), tfrs_rest_concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional - load from disk\n",
    "# tfrs_BP_concat = np.load(os.path.join(out_path, f'tfr_data_BP_617_subjects.npy'))\n",
    "# tfrs_rest_concat = np.load(os.path.join(out_path, f'tfr_data_rest_612_subjects.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average TFR arrays over beta range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define beta frequency range\n",
    "beta_freqs = np.argwhere((15 < freqs) & (freqs < 30))\n",
    "\n",
    "# Average over frequency. Uee axis=2 because frequency is the third axis in this array\n",
    "tfrs_rest_beta = np.mean(tfrs_rest_concat[:, :, beta_freqs, :], axis=2).squeeze()\n",
    "tfrs_bp_beta = np.mean(tfrs_bp_concat[:, :, beta_freqs, :], axis=2).squeeze() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "np.save(os.path.join(out_path, f'tfr_data_BP_beta_{n_subjects_bp}_subjects.npy'), tfrs_bp_beta)\n",
    "np.save(os.path.join(out_path, f'tfr_data_rest_beta_{n_subjects_rest}_subjects.npy'), tfrs_rest_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from disk\n",
    "tfrs_BP_beta = np.load(os.path.join(out_path, f'tfr_data_BP_beta_617_subjects.npy'))\n",
    "tfrs_rest_beta = np.load(os.path.join(out_path, f'tfr_data_rest_beta_612_subjects.npy'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
