{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "The purpose of this script is to compute \"long trial\" TFRs from the resting state data, based on a random selection of epochs equivalent to those selected for the button-press (BP) analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress output from mne unless it requires attention\n",
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define data directories and filenames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to raw data\n",
    "raw_path = os.path.join(\"/media/WDEasyStore/timb/camcan/download/20170824/cc700/meg/pipeline/release004/data_movecomp/aamod_meg_maxfilt_00002\")\n",
    "\n",
    "# Data path (from which we will read some files and write output)\n",
    "data_path = os.path.join(\"/media/NAS/lbailey/PMBR_timecourse/output\")\n",
    "\n",
    "# Path to Lindsey's proc data folder (containing ICA files for the resting state data)\n",
    "lpower_proc_data_path = os.path.join(\"/media/NAS/lpower/camcan/spectralEvents/rest/proc_data/\")\n",
    "\n",
    "# Define generic filenames\n",
    "raw_fif_fname = 'transdef_mf2pt2_rest_raw.fif'\n",
    "ica_fname = 'transdef_mf2pt2_rest_raw-ica.fif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import subjects list and BP trial timing information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the button-press trial timing data. \n",
    "df_trial_timings_allsubjects = pd.read_csv(os.path.join(data_path, \"trial_timings.csv\")).drop_duplicates(ignore_index=True) # Important: drop duplicates\n",
    "\n",
    "# Get list of subjects from the demographics csv\n",
    "df_demo_allsubjects = pd.read_csv(\"/home/timb/camcan/proc_data/demographics_allSubjects.csv\")\n",
    "subject_list = list(df_demo_allsubjects.loc[(df_demo_allsubjects['RawExists'] == 1)]['SubjectID'])\n",
    "\n",
    "# Remove the following subjects from subject_list. These subjects either had missing raw resting state data, or ICA failed to converge on their BP data\n",
    "missing_subjects = ['CC620685', 'CC620444', 'CC120208', 'CC621118', 'CC410097', \n",
    "                    'CC620557', 'CC723197', 'CC221733', 'CC711244', 'CC720330', \n",
    "                    'CC620567', 'CC122016', 'CC512003', 'CC610462', 'CC510480', \n",
    "                    'CC621080']\n",
    "\n",
    "for i in missing_subjects:\n",
    "    subject_list.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define timing parameters for selected events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time limits before and after the stimulus (i.e. time since the last trial and time until the next trial).\n",
    "# Note that these were the same constraints applied to the BP analysis\n",
    "pre_trial_time = 1\n",
    "post_trial_time = 15\n",
    "\n",
    "# Define suffix for output tfr file\n",
    "tfr_suffix = f'_epoch_tfrs_no_baseline_{pre_trial_time}s-pre_{post_trial_time}s-post_3-min_rest-tfr.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function to do the work**\n",
    "\n",
    "This will load the raw data, perform preprocessing, epoch according to our trial selection criteria, and compute and save TFRs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_long_rest_tfrs(subject):\n",
    "\n",
    "    # Define input files\n",
    "    raw_fif_path = os.path.join(raw_path, subject, 'rest', raw_fif_fname)\n",
    "    ica_path = os.path.join(lpower_proc_data_path, subject, ica_fname)\n",
    "\n",
    "    # Skip if the raw data file does not exist\n",
    "    if not os.path.exists(raw_fif_path):\n",
    "        print(f\"Skipping {subject} as raw data file does not exist\")\n",
    "        return\n",
    "\n",
    "    # Define output files\n",
    "    out_path = os.path.join(data_path, 'proc_data', subject)\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    tfr_path = os.path.join(out_path, f'{subject}_{tfr_suffix}')\n",
    "\n",
    "    print(tfr_path)\n",
    "\n",
    "    # Check Lindsey's proc_data directory for the ICA file. If it does not exist, \n",
    "    # check the output folder for this subject \n",
    "    if not os.path.exists(ica_path):\n",
    "        ica_path = os.path.join(out_path, ica_fname)\n",
    "\n",
    "    ica = mne.preprocessing.read_ica(ica_path)\n",
    "   \n",
    "\n",
    "    # Skip this subject if the TFR file already exists\n",
    "    if os.path.exists(tfr_path):\n",
    "        return\n",
    "\n",
    "    # We're going to segment the rest data into 16s epochs. Ultimately we want the same number of rest epochs as we have long BP epochs\n",
    "    # (per participant). So, we need to use the BP timing data to determine how many rest epochs we should extract.\n",
    "\n",
    "    # Pull the rows of df_demo_allsubjects and df_trial_timings_allsubjects for this subject\n",
    "    df_trial_timings = df_trial_timings_allsubjects[df_trial_timings_allsubjects['subject'] == subject]\n",
    "\n",
    "    # Subset rows of df_trial_timings to only include trials fitting our pre- and post-trial times\n",
    "    df_trial_timings_subset = df_trial_timings[(df_trial_timings['t_since_prev_trial'] >= pre_trial_time) \n",
    "                                        & (df_trial_timings['t_until_next_trial'] >= post_trial_time)]\n",
    "        \n",
    "    # Get the number of trials in this subset. This is the number of epochs we now want to extract from the rest data\n",
    "    n_epochs = len(df_trial_timings_subset)\n",
    "\n",
    "    # Define the length of our desired epochs\n",
    "    epoch_duration = (pre_trial_time + post_trial_time)\n",
    "\n",
    "\n",
    "    # Load the raw data\n",
    "    raw = mne.io.read_raw_fif(raw_fif_path, preload=True)\n",
    "\n",
    "    # Apply filtering\n",
    "    raw_filt = raw.copy().filter(0, 40)\n",
    "\n",
    "    # Epoch the raw data. MNE has a handy function to generate events of fixed length based on raw data. Note that we want epochs of length 16s, but we will add an extra 1s to the start and end of each epoch to avoid edge effects when it comes to computing the TFRs\n",
    "\n",
    "    # We'll take data from the middle 3 minutes of the scan. Note that the max N epochs we can extract in 3 minutes / 16s = 11.25 epochs. No subjects has more than 4 long BP trials\n",
    "    events = mne.make_fixed_length_events(raw_filt, \n",
    "                                          start = 170,  # start of 3-minute middle section\n",
    "                                          stop = 350,   # end of 3-minute middle section\n",
    "                                          duration = epoch_duration+2, overlap = 0)  \n",
    "\n",
    "    # Skip if there are no events\n",
    "    if len(events) == 0:\n",
    "        return\n",
    "    \n",
    "    # Perform epoching\n",
    "    epochs = mne.Epochs(raw_filt, events, tmin=-(pre_trial_time+1), tmax=(post_trial_time+1), baseline = None, preload=True)\n",
    "\n",
    "    # Select a random N epochs, where N == the number of long BP trials for this subject\n",
    "    epochs_subset = epochs[np.random.choice(range(len(epochs)), n_epochs, replace=False)]\n",
    "\n",
    "    if len(epochs_subset) == 0:\n",
    "        return\n",
    "\n",
    "    # Apply ICA to the epochs\n",
    "    epochs_icad = ica.apply(epochs_subset.load_data())\n",
    "\n",
    "    # Pick sensors of interest\n",
    "    epochs_icad_picks = epochs_icad.copy().pick(['MEG0211', 'MEG1311'])\n",
    "\n",
    "    # Set parameters for TFR\n",
    "    freqs = np.arange(1, 40, 1) \n",
    "    n_cycles = freqs / 2.0\n",
    "\n",
    "    # Compute TFR for each trial\n",
    "    tfr = epochs_icad_picks.compute_tfr(method='morlet', freqs=freqs, n_cycles=n_cycles, average=False, decim=10) \n",
    "\n",
    "    # Crop time back to our desired window, which will eliminate edge effects\n",
    "    tfr_cropped = tfr.copy().crop(tmin=-pre_trial_time, tmax=post_trial_time)\n",
    "\n",
    "    # Save the TFR to disk\n",
    "    tfr_cropped.save(tfr_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do the work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through subjects and compute trial TFR(s) for each\n",
    "for subject in tqdm(subject_list[:1]):\n",
    "    compute_long_rest_tfrs(subject)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
