{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "The purpose of this script is to isolate \"long\" button press events (occurring at least 1 s after and 15 s before adjacent button presses) in the raw MEG data, perform preprocessing and epoching, and then compute a tfr for each trial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mne.preprocessing import ICA, create_ecg_epochs, create_eog_epochs\n",
    "from statistics import mode\n",
    "\n",
    "# Suppress output from mne unless it requires attention\n",
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define data directories and filenames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to raw data\n",
    "raw_path = os.path.join(\"/media/WDEasyStore/timb/camcan/download/20170824/cc700/meg/pipeline/release004/data_movecomp/aamod_meg_maxfilt_00002\")\n",
    "\n",
    "# Data path (from which we will read some files and write output)\n",
    "data_path = os.path.join(\"/media/NAS/lbailey/PMBR_timecourse/output\")\n",
    "\n",
    "# Path to the event numpy files\n",
    "event_numpy_path = os.path.join(data_path, \"event_numpys\")\n",
    "\n",
    "# Path to Tim's old taskSensorAnalysis folder (containing ICA files and demographic csv file)\n",
    "timb_task_sensor_path = os.path.join(\"/home/timb/camcan/proc_data/\")\n",
    "\n",
    "# Define generic filenames\n",
    "raw_fif_fname = 'transdef_transrest_mf2pt2_task_raw.fif'\n",
    "ica_fname = 'transdef_transrest_mf2pt2_task_raw-ica.fif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import subject list and BP trial timing information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the trial timing and demographics data.\n",
    "df_trial_timings_allsubjects = pd.read_csv(os.path.join(data_path, \"trial_timings.csv\")).drop_duplicates(ignore_index=True) # Important: drop duplicates\n",
    "df_demo_allsubjects = pd.read_csv(os.path.join(timb_task_sensor_path, \"demographics_allSubjects.csv\"))\n",
    "\n",
    "# Get list of subjects from the demographics csv\n",
    "subject_list = list(df_demo_allsubjects.loc[(df_demo_allsubjects['RawExists'] == 1)]['SubjectID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define timing parameters for selected events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time limits before and after the stimulus (i.e. time since the last BP and time until the next BP)\n",
    "pre_trial_time = 1\n",
    "post_trial_time = 15\n",
    "\n",
    "# Define suffix for output tfr file\n",
    "tfr_suffix = f'_epoch_tfrs_no_baseline_{pre_trial_time}s-pre_{post_trial_time}s-post_BPtrial-tfr.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function to do the work**\n",
    "\n",
    "This will load the raw data, perform preprocessing, epoch according to our trial selection criteria, and compute and save TFRs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load the data, subset long trials, and compute TFRs\n",
    "def compute_long_bp_tfrs(subject): \n",
    "\n",
    "    # Define input files\n",
    "    raw_fif_path = os.path.join(raw_path, subject, 'task', raw_fif_fname)\n",
    "    events_path = os.path.join(event_numpy_path, subject + '-eve.txt')\n",
    "    ica_path = os.path.join(timb_task_sensor_path, 'TaskSensorAnalysis_transdef', subject, ica_fname)\n",
    "\n",
    "    # Define output files    \n",
    "    out_path = os.path.join(data_path, 'proc_data', subject)\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    tfr_path = os.path.join(out_path, f'{subject}_{tfr_suffix}')  \n",
    "\n",
    "    # Skip if the output file already exists\n",
    "    if os.path.exists(tfr_path):\n",
    "\n",
    "        print(\"Skipping subject \" + subject + \" because the output file already exists\")\n",
    "\n",
    "    #     # Some hd5 files have been corrupted, causing \"OSError: Can't synchronously read data (inflate() failed)\"\n",
    "    #     # when trying to load them. We'll try to catch the error: if it occurs, delete the file and recompute it.\n",
    "    #     try:\n",
    "    #         tfr = mne.time_frequency.read_tfrs(tfr_path)[0]\n",
    "    #         return # return if the file exists and does not cuase an error\n",
    "    #     except OSError:\n",
    "    #         print(\"Deleting corrupted file: \" + tfr_path)\n",
    "    #         os.remove(tfr_path)\n",
    "\n",
    "\n",
    "    # If raw or events files do not exist, skip\n",
    "    if not os.path.exists(raw_fif_path):\n",
    "        print(\"Skipping subject \" + subject + \" because raw file does not exist\")\n",
    "        return\n",
    "    if not os.path.exists(events_path):\n",
    "        print(\"Skipping subject \" + subject + \" because events file does not exist\")\n",
    "        return\n",
    "\n",
    "    # Pull the rows of df_demo_allsubjects and df_trial_timings_allsubjects for this subject\n",
    "    df_trial_timings = df_trial_timings_allsubjects[df_trial_timings_allsubjects['subject'] == subject]\n",
    "\n",
    "    # Subset rows of df_trial_timings to only include trials fitting our pre- and post-trial times\n",
    "    df_trial_timings_subset = df_trial_timings[(df_trial_timings['t_since_prev_trial'] >= pre_trial_time) \n",
    "                                        & (df_trial_timings['t_until_next_trial'] >= post_trial_time)]\n",
    "\n",
    "    # Convert this_trial_t to ms\n",
    "    this_trial_t = df_trial_timings_subset['this_trial_t']*1000\n",
    "\n",
    "    # Read in the events file for this subject    \n",
    "    events = mne.read_events(events_path)\n",
    "\n",
    "    # Select button press events (the most frequent trigger type)\n",
    "    events_bp = events[events[:,2] == mode(events[:,2])] \n",
    "\n",
    "    # Find rows of events where onset time matches elements of this_trial_t\n",
    "    events_bp_long = events_bp[np.isin([i[0] for i in events_bp], this_trial_t), :]\n",
    "\n",
    "    # Pass if there are no events fitting our criteria\n",
    "    if events_bp_long.size==0:\n",
    "        print(\"Skipping subject \" + subject + \" because there are no events fitting our criteria\")\n",
    "        return\n",
    "\n",
    "    # Read raw data\n",
    "    raw = mne.io.read_raw_fif(raw_fif_path, preload=True)                                                                                      \n",
    "\n",
    "    # Apply filtering\n",
    "    raw_filt = raw.copy().filter(0, 40)\n",
    "\n",
    "    # Epoch the raw data. Note that our epochs will be 1s wider (on either side) than pre/post_trial_time, to avoid edge effects \n",
    "    # in the final tfrs. We will crop the tfrs by 1 sec on either side later on\n",
    "    epochs = mne.Epochs(raw_filt, events_bp_long, tmin=-(pre_trial_time+1), tmax=(post_trial_time+1), baseline=None) \n",
    "\n",
    "    # Load pre-computed ICA file from Tim's old TaskSensor folder.\n",
    "    try:\n",
    "        ica = mne.preprocessing.read_ica(ica_path)\n",
    "    \n",
    "    # If it does not exist, look for it in this subject's output directory\n",
    "    except FileNotFoundError:\n",
    "        print(\"ICA file not found in Tim's TaskSensorAnalysis folder. Looking in our output directory.\")\n",
    "        try:\n",
    "            new_ica_path = os.path.join(out_path, os.path.basename(ica_path))\n",
    "            ica = mne.preprocessing.read_ica(new_ica_path)\n",
    "    \n",
    "        # If the ica file does not exist in our output directory, compute ICA here\n",
    "        except FileNotFoundError:\n",
    "\n",
    "            print('!! Running ICA !!')\n",
    "            reject = dict(grad=4000e-13, mag=5e-12)\n",
    "            picks = mne.pick_types(raw.info, meg=True, eeg=False, eog=True,\n",
    "                                stim=False, exclude='bads')\n",
    "            \n",
    "            ica = ICA(n_components=0.99, method='fastica')\n",
    "\n",
    "            # Added by LB due to ica.fit() throwing a Runtime Error (No clean segment found) on subject CC510395\n",
    "            try:  # Added by LB\n",
    "                ica.fit(raw, picks=picks, reject=reject)  # indented by LB\n",
    "            except:  # Added by LB\n",
    "                print('## Failed to fit ICA ##')\n",
    "                return # Added by LB\n",
    "\n",
    "            n_max_ecg, n_max_eog = 3, 3\n",
    "\n",
    "            # Reject bad EOG components following mne procedure\n",
    "            try:\n",
    "                eog_epochs = create_eog_epochs(raw, tmin=-0.5, tmax=0.5, reject=reject)\n",
    "                eog_inds, scores = ica.find_bads_eog(eog_epochs)\n",
    "                eog_inds = eog_inds[:n_max_eog]\n",
    "                ica.exclude.extend(eog_inds)\n",
    "            except:\n",
    "                print(\"\"\"Subject {0} had no eog/eeg channels\"\"\".format(str(subject)))\n",
    "\n",
    "            # Reject bad ECG compoments following mne procedure\n",
    "            ecg_epochs = create_ecg_epochs(raw, tmin=-0.5, tmax=0.5)\n",
    "            ecg_inds, scores = ica.find_bads_ecg(ecg_epochs, method='ctps')\n",
    "            ecg_inds = ecg_inds[:n_max_ecg]\n",
    "            ica.exclude.extend(ecg_inds)   \n",
    "\n",
    "            # Save ICA to this subject's output folder\n",
    "            ica.save(new_ica_path)\n",
    "\n",
    "    # Apply ica to the epochs\n",
    "    epochs_icad = ica.apply(epochs.load_data())\n",
    "\n",
    "    # Pick sensors of interest\n",
    "    epochs_icad_picks = epochs_icad.copy().pick(['MEG0211', 'MEG1311'])\n",
    "\n",
    "    # Set parameters for TFR\n",
    "    freqs = np.arange(1, 40, 1) \n",
    "    n_cycles = freqs / 2.0\n",
    "\n",
    "    # Compute TFR for each trial\n",
    "    tfr = epochs_icad_picks.compute_tfr(method='morlet', freqs=freqs, n_cycles=n_cycles, average=False, decim=10) \n",
    "\n",
    "    # Crop time back to our desired window, which will eliminate edge effects\n",
    "    tfr_cropped = tfr.copy().crop(tmin=-pre_trial_time, tmax=post_trial_time)\n",
    "\n",
    "    # Save to disk\n",
    "    tfr_cropped.save(tfr_path, overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do the work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through subjects and compute trial TFR(s) for each\n",
    "for subject in tqdm(subject_list[:1]):\n",
    "    compute_long_bp_tfrs(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject_list[:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
